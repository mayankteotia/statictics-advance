{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86669e6a-4301-47c6-b769-208caf0e27d6",
   "metadata": {},
   "source": [
    "Q1-> Define the z-statistic and explain its relationship to the standard normal distribution. How is the\n",
    "z-statistic used in hypothesis testing\n",
    "\n",
    "ANS-> Definition of the Z-Statistic\n",
    "\n",
    "The z-statistic (or z-score) is a measure that describes how many standard deviations a data point or sample statistic is from the population mean. It is calculated using the formula:\n",
    "\n",
    "\n",
    "z = \\frac{X - \\mu}{\\sigma}\n",
    "\n",
    "\n",
    "Where:\n",
    "( X ) is the observed value or sample statistic (e.g., sample mean),\n",
    "( mu ) is the population mean,\n",
    "( sigma ) is the population standard deviation.\n",
    "\n",
    "When dealing with sample data and estimating the population standard deviation, the formula is adjusted as:\n",
    "\n",
    "\n",
    "z = frac{\\bar{X} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n",
    "\n",
    "\n",
    "Where:\n",
    "- \\( \\bar{X} \\) is the sample mean,\n",
    "- \\( n \\) is the sample size.\n",
    "\n",
    "### Relationship to the Standard Normal Distribution\n",
    "\n",
    "The z-statistic corresponds to the standard normal distribution, a bell-shaped curve with:\n",
    "- A mean (\\( \\mu \\)) of 0,\n",
    "- A standard deviation (\\( \\sigma \\)) of 1.\n",
    "\n",
    "By converting raw data into z-scores, we standardize different datasets to allow for comparison or analysis using the properties of the standard normal distribution. \n",
    "\n",
    "In this framework:\n",
    "- A z-score of \\( 0 \\) indicates the value is exactly at the mean.\n",
    "- Positive z-scores indicate values above the mean, while negative z-scores indicate values below the mean.\n",
    "\n",
    "### Use of the Z-Statistic in Hypothesis Testing\n",
    "\n",
    "In hypothesis testing, the z-statistic helps determine how likely it is for the sample data to occur under the null hypothesis (\\( H_0 \\)). Hereâ€™s how it is typically used:\n",
    "\n",
    "1. **Formulate Hypotheses:**\n",
    "   - Null hypothesis (\\( H_0 \\)): Assumes no effect or no difference.\n",
    "   - Alternative hypothesis (\\( H_a \\)): Assumes an effect or difference.\n",
    "\n",
    "2. **Calculate the Z-Statistic:**\n",
    "   Use sample data to compute the z-score, representing the deviation of the sample statistic from the hypothesized population parameter under \\( H_0 \\).\n",
    "\n",
    "3. **Determine the P-Value:**\n",
    "   Using the z-score, find the corresponding p-value (the probability of observing a z-score as extreme or more extreme, assuming \\( H_0 \\) is true) from the standard normal distribution table.\n",
    "\n",
    "4. **Compare to the Significance Level (\\( \\alpha \\)):**\n",
    "   - If \\( p \\leq \\alpha \\), reject \\( H_0 \\) (evidence suggests the alternative hypothesis is true).\n",
    "   - If \\( p > \\alpha \\), fail to reject \\( H_0 \\) (not enough evidence to support \\( H_a \\)).\n",
    "\n",
    "### Example in Context\n",
    "\n",
    "If testing whether a new medication alters blood pressure, you might hypothesize:\n",
    "- \\( H_0 \\): The mean change in blood pressure is 0 (\\( \\mu = 0 \\)).\n",
    "- \\( H_a \\): The mean change in blood pressure is not 0 (\\( \\mu \\neq 0 \\)).\n",
    "\n",
    "After collecting sample data, the z-statistic quantifies how far the observed mean change in blood pressure is from 0 (under \\( H_0 \\)), guiding the decision to accept or reject \\( H_0 \\).\n",
    "\n",
    "This process assumes the sampling distribution of the test statistic is approximately normal, which is valid under large sample sizes or when population characteristics are known."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def20319-d436-4f0e-b57a-58141c36a38d",
   "metadata": {},
   "source": [
    "Q2-> : What is a p-value, and how is it used in hypothesis testing? What does it mean if the p-value is\n",
    "very small (e.g., 0.01)?\n",
    "\n",
    "ANS-> ### What is a P-Value?\n",
    "\n",
    "A **p-value** is the probability of observing a test statistic (e.g., a z-score, t-statistic) as extreme as, or more extreme than, the one calculated from the sample data, assuming the null hypothesis (\\( H_0 \\)) is true. \n",
    "\n",
    "It quantifies how compatible the observed data are with the null hypothesis:\n",
    "- A high p-value suggests that the observed data are consistent with \\( H_0 \\).\n",
    "- A low p-value suggests that the observed data are unlikely under \\( H_0 \\).\n",
    "\n",
    "### Use of the P-Value in Hypothesis Testing\n",
    "\n",
    "The p-value is used as a tool for deciding whether to reject the null hypothesis:\n",
    "1. **Set a Significance Level (\\( \\alpha \\)):**\n",
    "   - Common choices are \\( \\alpha = 0.05 \\) or \\( \\alpha = 0.01 \\).\n",
    "   - \\( \\alpha \\) is the threshold probability for deciding whether to reject \\( H_0 \\).\n",
    "\n",
    "2. **Compare the P-Value to \\( \\alpha \\):**\n",
    "   - If \\( \\text{p-value} \\leq \\alpha \\): Reject \\( H_0 \\), indicating that the result is statistically significant.\n",
    "   - If \\( \\text{p-value} > \\alpha \\): Fail to reject \\( H_0 \\), indicating insufficient evidence to support the alternative hypothesis (\\( H_a \\)).\n",
    "\n",
    "### Interpretation of a Very Small P-Value (e.g., 0.01)\n",
    "\n",
    "If the p-value is very small, such as 0.01, this implies:\n",
    "- The observed result is highly unlikely under \\( H_0 \\).\n",
    "- There is strong evidence against the null hypothesis, favoring the alternative hypothesis.\n",
    "\n",
    "For example, if \\( \\alpha = 0.05 \\) and the p-value is 0.01:\n",
    "- The result is statistically significant because \\( 0.01 < 0.05 \\).\n",
    "- This means the observed data is very unlikely to occur due to random chance if \\( H_0 \\) were true.\n",
    "\n",
    "### Important Notes on P-Values\n",
    "\n",
    "1. **Not the Probability That \\( H_0 \\) is True:**\n",
    "   A p-value does not directly measure the probability that the null hypothesis is true or false.\n",
    "\n",
    "2. **Magnitude of the Effect:**\n",
    "   A small p-value indicates statistical significance but does not measure the size or practical importance of the effect.\n",
    "\n",
    "3. **Context Matters:**\n",
    "   Statistical significance (small p-value) does not always imply practical significance. The results should be interpreted in the context of the research question and real-world implications.\n",
    "\n",
    "In summary, a very small p-value suggests strong evidence against \\( H_0 \\), prompting rejection of the null hypothesis under the predefined significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c3e2ae-6676-4638-9760-6a3e801a83a0",
   "metadata": {},
   "source": [
    "Q3->: Compare and contrast the binomial and Bernoulli distributions. \n",
    "\n",
    "ANS-> ### Comparison and Contrast: Binomial vs. Bernoulli Distributions\n",
    "\n",
    "The **binomial distribution** and the **Bernoulli distribution** are closely related probability distributions used in statistics, particularly for modeling discrete random variables. Here's a detailed comparison:\n",
    "\n",
    "---\n",
    "\n",
    "| **Aspect**              | **Bernoulli Distribution**                          | **Binomial Distribution**                                   |\n",
    "|-------------------------|----------------------------------------------------|-----------------------------------------------------------|\n",
    "| **Definition**          | Models the outcome of a single trial with two possible outcomes (success or failure). | Models the number of successes in a fixed number of independent Bernoulli trials. |\n",
    "| **Random Variable**     | \\( X \\in \\{0, 1\\} \\)                               | \\( X \\in \\{0, 1, 2, \\dots, n\\} \\), where \\( n \\) is the number of trials. |\n",
    "| **Parameters**          | \\( p \\): Probability of success.                  | \\( n \\): Number of trials; \\( p \\): Probability of success per trial. |\n",
    "| **Probability Mass Function (PMF)** | \\( P(X = x) = p^x (1-p)^{1-x} \\), for \\( x \\in \\{0, 1\\} \\). | \\( P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k} \\), for \\( k \\in \\{0, 1, \\dots, n\\} \\). |\n",
    "| **Mean (\\( \\mu \\))**    | \\( \\mu = p \\)                                      | \\( \\mu = n \\cdot p \\)                                      |\n",
    "| **Variance (\\( \\sigma^2 \\))** | \\( \\sigma^2 = p(1-p) \\)                        | \\( \\sigma^2 = n \\cdot p \\cdot (1-p) \\)                    |\n",
    "| **Number of Trials**    | Single trial (\\( n = 1 \\)).                        | Multiple trials (\\( n \\geq 1 \\)).                         |\n",
    "| **Use Case**            | Describes the outcome of a single event (e.g., flipping a coin once). | Describes the total number of successes across multiple trials (e.g., flipping a coin \\( n \\) times). |\n",
    "| **Relationship**        | A binomial distribution with \\( n = 1 \\) is equivalent to a Bernoulli distribution. | A Bernoulli distribution is a special case of the binomial distribution when \\( n = 1 \\). |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "1. **Number of Trials:**\n",
    "   - The Bernoulli distribution is concerned with a single trial.\n",
    "   - The binomial distribution generalizes this to \\( n \\) independent trials.\n",
    "\n",
    "2. **Range of Outcomes:**\n",
    "   - In the Bernoulli distribution, the outcome is binary (\\( 0 \\) or \\( 1 \\)).\n",
    "   - In the binomial distribution, the outcome is the count of successes, ranging from \\( 0 \\) to \\( n \\).\n",
    "\n",
    "3. **Parameters:**\n",
    "   - The Bernoulli distribution is defined only by \\( p \\), the probability of success.\n",
    "   - The binomial distribution requires two parameters: \\( n \\) (number of trials) and \\( p \\) (probability of success).\n",
    "\n",
    "### Relationship Between the Two\n",
    "- The binomial distribution is essentially a sum of \\( n \\) independent Bernoulli trials. If \\( X_1, X_2, \\dots, X_n \\) are independent Bernoulli random variables with success probability \\( p \\), then their sum:\n",
    "  \\[\n",
    "  S = \\sum_{i=1}^n X_i\n",
    "  \\]\n",
    "  follows a binomial distribution with parameters \\( n \\) and \\( p \\).\n",
    "\n",
    "### Example\n",
    "- **Bernoulli Distribution:** Tossing a single coin with \\( p = 0.5 \\). Possible outcomes are:\n",
    "  \\[\n",
    "  P(X = 1) = 0.5, \\quad P(X = 0) = 0.5\n",
    "  \\]\n",
    "- **Binomial Distribution:** Tossing a coin 5 times with \\( p = 0.5 \\). Possible outcomes are counts of heads:\n",
    "  \\[\n",
    "  P(X = k) = \\binom{5}{k} (0.5)^k (0.5)^{5-k}, \\quad k = 0, 1, 2, 3, 4, 5\n",
    "  \\]\n",
    "\n",
    "In summary, the Bernoulli distribution models individual trials, while the binomial distribution aggregates results across multiple trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb75d8-571d-41f2-8741-d53a3989675a",
   "metadata": {},
   "source": [
    "Q4-> Under what conditions is the binomial distribution used, and how does it relate to the Bernoulli\n",
    "distribution?\n",
    "\n",
    "ANS->\n",
    "### **Conditions for Using the Binomial Distribution**\n",
    "\n",
    "The **binomial distribution** is used when the following conditions are met:\n",
    "\n",
    "1. **Fixed Number of Trials (\\( n \\)):**\n",
    "   - The experiment consists of a specific number of trials, \\( n \\), which is predetermined and finite.\n",
    "\n",
    "2. **Binary Outcomes:**\n",
    "   - Each trial has exactly two possible outcomes, typically labeled as \"success\" and \"failure.\"\n",
    "\n",
    "3. **Constant Probability of Success (\\( p \\)):**\n",
    "   - The probability of success (\\( p \\)) remains the same for each trial.\n",
    "\n",
    "4. **Independence of Trials:**\n",
    "   - The outcome of one trial does not influence the outcomes of other trials.\n",
    "\n",
    "5. **Discrete Count of Successes:**\n",
    "   - The variable of interest is the total count of successes across \\( n \\) trials.\n",
    "\n",
    "### **Relationship to the Bernoulli Distribution**\n",
    "\n",
    "The **binomial distribution** is a generalization of the **Bernoulli distribution**:\n",
    "- A Bernoulli distribution describes the outcome of a **single trial** with two possible outcomes (success or failure) and a fixed probability of success (\\( p \\)).\n",
    "- The binomial distribution describes the **sum of outcomes** from multiple independent Bernoulli trials.\n",
    "\n",
    "Mathematically:\n",
    "- If \\( X_1, X_2, \\dots, X_n \\) are \\( n \\) independent random variables, each following a Bernoulli distribution with probability \\( p \\), then their sum:\n",
    "  \\[\n",
    "  S = \\sum_{i=1}^n X_i\n",
    "  \\]\n",
    "  follows a binomial distribution with parameters \\( n \\) (number of trials) and \\( p \\) (probability of success).\n",
    "\n",
    "### **Key Differences**\n",
    "\n",
    "| Aspect                 | Bernoulli Distribution            | Binomial Distribution                  |\n",
    "|------------------------|------------------------------------|----------------------------------------|\n",
    "| **Trials**             | Single trial (\\( n = 1 \\))        | Multiple trials (\\( n \\geq 1 \\))       |\n",
    "| **Random Variable**    | Binary outcome (\\( X \\in \\{0, 1\\} \\)) | Count of successes (\\( X \\in \\{0, 1, ..., n\\} \\)) |\n",
    "| **Parameters**         | \\( p \\): Probability of success   | \\( n \\): Number of trials, \\( p \\): Probability of success |\n",
    "\n",
    "### **When to Use the Binomial Distribution**\n",
    "The binomial distribution is used in scenarios where you count the number of successes in repeated independent trials. Examples include:\n",
    "- Tossing a coin \\( n \\) times and counting the number of heads.\n",
    "- Counting the number of defective items in a batch of \\( n \\) products.\n",
    "- Surveying \\( n \\) people to determine how many favor a particular candidate.\n",
    "\n",
    "### **Summary**\n",
    "- The **binomial distribution** is applied to a sequence of independent Bernoulli trials.\n",
    "- The **Bernoulli distribution** is the building block for the binomial distribution, modeling the result of a single trial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8671a6-a254-41e6-8521-b8700b157eaf",
   "metadata": {},
   "source": [
    "Q5-> What are the key properties of the Poisson distribution, and when is it appropriate to use this\n",
    "distribution?\n",
    "\n",
    "ANS->\n",
    "### **Key Properties of the Poisson Distribution**\n",
    "\n",
    "The **Poisson distribution** is a discrete probability distribution used to model the number of events occurring in a fixed interval of time, space, or other continuous dimensions, given certain conditions. Its key properties are:\n",
    "\n",
    "1. **Probability Mass Function (PMF):**\n",
    "   - The probability of observing \\( k \\) events is given by:\n",
    "     \\[\n",
    "     P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}, \\quad k = 0, 1, 2, \\dots\n",
    "     \\]\n",
    "   - Here:\n",
    "     - \\( \\lambda \\) is the average rate (mean) of events occurring in the given interval.\n",
    "     - \\( e \\) is the base of the natural logarithm (\\( \\approx 2.718 \\)).\n",
    "\n",
    "2. **Mean and Variance:**\n",
    "   - The mean (\\( \\mu \\)) and variance (\\( \\sigma^2 \\)) of a Poisson random variable are both equal to \\( \\lambda \\):\n",
    "     \\[\n",
    "     \\mu = \\lambda, \\quad \\sigma^2 = \\lambda\n",
    "     \\]\n",
    "\n",
    "3. **Skewness:**\n",
    "   - The distribution is positively skewed, but the skewness decreases as \\( \\lambda \\) increases, approaching a normal distribution.\n",
    "\n",
    "4. **Memoryless Property:**\n",
    "   - The Poisson process assumes that the probability of an event occurring is independent of when the last event occurred (similar to the exponential distribution).\n",
    "\n",
    "5. **Additivity:**\n",
    "   - If \\( X_1 \\sim \\text{Poisson}(\\lambda_1) \\) and \\( X_2 \\sim \\text{Poisson}(\\lambda_2) \\), and they are independent, then:\n",
    "     \\[\n",
    "     X_1 + X_2 \\sim \\text{Poisson}(\\lambda_1 + \\lambda_2)\n",
    "     \\]\n",
    "\n",
    "---\n",
    "\n",
    "### **When is it Appropriate to Use the Poisson Distribution?**\n",
    "\n",
    "The Poisson distribution is appropriate when the following conditions are met:\n",
    "\n",
    "1. **Events Occur Randomly and Independently:**\n",
    "   - The occurrence of one event does not influence the occurrence of another.\n",
    "\n",
    "2. **Constant Rate (\\( \\lambda \\)):**\n",
    "   - The average number of events per unit interval is constant.\n",
    "\n",
    "3. **Discrete Events:**\n",
    "   - The events being counted are discrete occurrences (e.g., customer arrivals, phone calls).\n",
    "\n",
    "4. **Non-Overlapping Intervals:**\n",
    "   - Events occurring in disjoint intervals are independent.\n",
    "\n",
    "5. **Small Probability for Each Event:**\n",
    "   - The probability of an event occurring in a very small sub-interval is proportional to the length of the sub-interval.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples of Appropriate Use**\n",
    "\n",
    "1. **Counting Events Over Time:**\n",
    "   - Number of emails received in an hour.\n",
    "   - Number of customer arrivals at a store in a day.\n",
    "\n",
    "2. **Counting Events Over Space:**\n",
    "   - Number of potholes in a stretch of road.\n",
    "   - Number of trees in a fixed area of forest.\n",
    "\n",
    "3. **Rare Events:**\n",
    "   - Number of accidents at a particular intersection in a year.\n",
    "   - Number of mutations in a segment of DNA.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "The Poisson distribution models **counts of rare events** occurring in a fixed interval, assuming the events occur independently and at a constant average rate. Its simplicity and flexibility make it widely applicable in fields like telecommunications, biology, and traffic engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94155cc9-1680-4106-9f12-c3ea4978b7a9",
   "metadata": {},
   "source": [
    "Q6-> Define the terms \"probability distribution\" and \"probability density function\" (PDF). How does a\n",
    "PDF differ from a probability mass function (PMF)?\n",
    "\n",
    "ANS->\n",
    "### **Probability Distribution**\n",
    "\n",
    "A **probability distribution** describes how the probabilities of a random variable are distributed over its possible values. It provides a mathematical framework for modeling the likelihood of outcomes of a random phenomenon.\n",
    "\n",
    "- For **discrete random variables**, it is typically represented using a **probability mass function (PMF)**.\n",
    "- For **continuous random variables**, it is typically represented using a **probability density function (PDF)**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Probability Density Function (PDF)**\n",
    "\n",
    "A **probability density function (PDF)** is a function that describes the relative likelihood of a continuous random variable taking on a specific value. The key features of a PDF are:\n",
    "\n",
    "1. **Non-Negativity:**\n",
    "   \\[\n",
    "   f(x) \\geq 0 \\quad \\text{for all } x\n",
    "   \\]\n",
    "\n",
    "2. **Total Area Equals 1:**\n",
    "   \\[\n",
    "   \\int_{-\\infty}^{\\infty} f(x) \\, dx = 1\n",
    "   \\]\n",
    "\n",
    "3. **Probability Interpretation:**\n",
    "   - For a continuous random variable \\( X \\) with PDF \\( f(x) \\), the probability that \\( X \\) lies within an interval \\([a, b]\\) is given by:\n",
    "     \\[\n",
    "     P(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx\n",
    "     \\]\n",
    "   - The value of \\( f(x) \\) at a specific point does not represent the probability of \\( X = x \\); instead, it reflects the density of the probability around \\( x \\).\n",
    "\n",
    "---\n",
    "\n",
    "### **Probability Mass Function (PMF)**\n",
    "\n",
    "A **probability mass function (PMF)** is a function that provides the probabilities of a discrete random variable taking on each of its possible values. The key features of a PMF are:\n",
    "\n",
    "1. **Non-Negativity:**\n",
    "   \\[\n",
    "   P(X = x_i) \\geq 0 \\quad \\text{for all } x_i\n",
    "   \\]\n",
    "\n",
    "2. **Total Sum Equals 1:**\n",
    "   \\[\n",
    "   \\sum_{i} P(X = x_i) = 1\n",
    "   \\]\n",
    "\n",
    "3. **Probability Interpretation:**\n",
    "   - For a discrete random variable \\( X \\) with PMF \\( P(X = x_i) \\), the probability of \\( X \\) taking the specific value \\( x_i \\) is exactly \\( P(X = x_i) \\).\n",
    "\n",
    "---\n",
    "\n",
    "### **Differences Between PDF and PMF**\n",
    "\n",
    "| Aspect                    | PDF (Probability Density Function)            | PMF (Probability Mass Function)                  |\n",
    "|---------------------------|-----------------------------------------------|-------------------------------------------------|\n",
    "| **Random Variable Type**  | Continuous                                   | Discrete                                        |\n",
    "| **Values of the Function**| Represents probability density, not direct probabilities. | Represents probabilities directly.             |\n",
    "| **Sum or Area**           | The total area under the curve is 1.         | The total sum of probabilities is 1.           |\n",
    "| **Probability Calculation**| Requires integration over an interval.       | Probabilities are given directly for specific values. |\n",
    "| **Example**               | Normal distribution: \\( f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\). | Binomial distribution: \\( P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k} \\). |\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- A **probability distribution** describes how probabilities are allocated to outcomes of a random variable.\n",
    "- A **PDF** is used for continuous random variables and describes the density of probabilities, requiring integration to calculate probabilities over intervals.\n",
    "- A **PMF** is used for discrete random variables and directly gives the probabilities of specific outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb549cc2-98b8-43e5-9999-4b4382375d84",
   "metadata": {},
   "source": [
    "Q7->\n",
    " Explain the Central Limit Theorem (CLT) with example\n",
    "\n",
    "ANS->\n",
    "### **Central Limit Theorem (CLT)**\n",
    "\n",
    "The **Central Limit Theorem (CLT)** states that, given a sufficiently large sample size, the sampling distribution of the sample mean will approach a normal distribution, regardless of the original population's distribution. This is true as long as the population has a finite mean (\\( \\mu \\)) and variance (\\( \\sigma^2 \\)).\n",
    "\n",
    "### **Key Points of the CLT**\n",
    "\n",
    "1. **Sample Size:**\n",
    "   - The larger the sample size (\\( n \\)), the closer the sampling distribution of the sample mean (\\( \\bar{X} \\)) will be to a normal distribution.\n",
    "\n",
    "2. **Mean and Standard Error:**\n",
    "   - The mean of the sampling distribution is equal to the population mean:\n",
    "     \\[\n",
    "     \\mu_{\\bar{X}} = \\mu\n",
    "     \\]\n",
    "   - The standard deviation of the sampling distribution (standard error) is:\n",
    "     \\[\n",
    "     \\sigma_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}}\n",
    "     \\]\n",
    "     where \\( \\sigma \\) is the population standard deviation.\n",
    "\n",
    "3. **Applies Regardless of Population Shape:**\n",
    "   - The original population distribution can be normal, skewed, or any other shape, but the sampling distribution of the mean will be approximately normal.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example of the Central Limit Theorem**\n",
    "\n",
    "#### **Scenario:**\n",
    "Suppose a factory produces light bulbs, and the lifespans of these bulbs follow an exponential distribution with a mean lifespan (\\( \\mu \\)) of 1000 hours and a standard deviation (\\( \\sigma \\)) of 500 hours.\n",
    "\n",
    "#### **Step 1: Single Sample vs. Sampling Distribution**\n",
    "- If we randomly select one light bulb, its lifespan is likely to follow the exponential distribution, which is highly skewed.\n",
    "- However, if we take random samples of 50 bulbs and calculate the sample mean lifespan for each sample, the distribution of these sample means will approach a normal distribution as per the CLT.\n",
    "\n",
    "#### **Step 2: Calculating the Sampling Distribution**\n",
    "- Population mean (\\( \\mu \\)) = 1000 hours.\n",
    "- Population standard deviation (\\( \\sigma \\)) = 500 hours.\n",
    "- Sample size (\\( n \\)) = 50.\n",
    "\n",
    "The mean of the sampling distribution:\n",
    "\\[\n",
    "\\mu_{\\bar{X}} = \\mu = 1000 \\, \\text{hours}.\n",
    "\\]\n",
    "\n",
    "The standard error of the sampling distribution:\n",
    "\\[\n",
    "\\sigma_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{500}{\\sqrt{50}} \\approx 70.71 \\, \\text{hours}.\n",
    "\\]\n",
    "\n",
    "#### **Step 3: Application**\n",
    "- If we take many samples of 50 bulbs and plot the sample means, the resulting distribution will be approximately normal, centered at 1000 hours, with a standard deviation of 70.71 hours.\n",
    "- This approximation allows us to apply statistical methods that assume normality, even though the original distribution (exponential) is not normal.\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Importance of the CLT**\n",
    "\n",
    "1. **Simplifies Analysis:**\n",
    "   - Many statistical methods rely on the assumption of normality. The CLT enables their use with non-normal populations when sample sizes are large.\n",
    "\n",
    "2. **Real-World Applications:**\n",
    "   - Quality control in manufacturing.\n",
    "   - Estimation of population parameters (e.g., polling data, average test scores).\n",
    "\n",
    "### **Visualization of the CLT**\n",
    "Imagine rolling a die:\n",
    "- Rolling the die once produces a uniform distribution (each number 1â€“6 has equal probability).\n",
    "- Rolling it 30 times and taking the average (mean) of those rolls repeatedly produces a sampling distribution of means, which will approach a normal distribution as more rolls and samples are taken.\n",
    "\n",
    "In summary, the CLT is a cornerstone of inferential statistics, providing the foundation for making predictions and inferences about population parameters from sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a018cfe-45aa-46b2-97c4-4c3d68cabd7c",
   "metadata": {},
   "source": [
    "Q8-> Compare z-scores and t-scores. When should you use a z-score, and when should a t-score be a\n",
    "pplied instead?\n",
    "\n",
    "ANS->\n",
    "### **Comparison of Z-Scores and T-Scores**\n",
    "\n",
    "| **Aspect**                | **Z-Score**                                  | **T-Score**                                   |\n",
    "|---------------------------|----------------------------------------------|-----------------------------------------------|\n",
    "| **Definition**            | Measures how many standard deviations a data point is from the population mean. | Similar to z-score but accounts for uncertainty in small sample sizes. |\n",
    "| **Formula**               | \\[\n",
    "z = \\frac{\\bar{X} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n",
    "\\] | \\[\n",
    "t = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}}\n",
    "\\] |\n",
    "| **Distribution**          | Based on the standard normal distribution (mean = 0, standard deviation = 1). | Based on the t-distribution, which has heavier tails than the normal distribution. |\n",
    "| **Known vs. Unknown Variance** | Assumes the population standard deviation (\\( \\sigma \\)) is known. | Used when the population standard deviation is unknown and the sample standard deviation (\\( s \\)) is used instead. |\n",
    "| **Sample Size**           | Typically applied to large sample sizes (\\( n > 30 \\)). | Typically applied to small sample sizes (\\( n \\leq 30 \\)). |\n",
    "| **Shape of Distribution** | Symmetric and bell-shaped.                  | Symmetric and bell-shaped, but with heavier tails (more spread out), especially for small sample sizes. |\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use a Z-Score**\n",
    "\n",
    "1. **Population Standard Deviation Known:**\n",
    "   - Use a z-score when the population standard deviation (\\( \\sigma \\)) is known.\n",
    "\n",
    "2. **Large Sample Size:**\n",
    "   - For large sample sizes (\\( n > 30 \\)), the sample standard deviation (\\( s \\)) approximates the population standard deviation (\\( \\sigma \\)), making the z-score appropriate.\n",
    "\n",
    "3. **Examples:**\n",
    "   - Comparing a test score to the population mean when the population variance is well-documented.\n",
    "   - Evaluating a sample mean when working with a large dataset and known variance.\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use a T-Score**\n",
    "\n",
    "1. **Population Standard Deviation Unknown:**\n",
    "   - Use a t-score when the population standard deviation (\\( \\sigma \\)) is unknown, and the sample standard deviation (\\( s \\)) is used as an estimate.\n",
    "\n",
    "2. **Small Sample Size:**\n",
    "   - For small sample sizes (\\( n \\leq 30 \\)), the t-distribution accounts for the additional variability introduced by estimating \\( \\sigma \\) with \\( s \\).\n",
    "\n",
    "3. **Examples:**\n",
    "   - Analyzing the average test scores of a class of 15 students when the population standard deviation is unknown.\n",
    "   - Hypothesis testing for the mean of a small sample from an unknown population.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why the Difference Matters**\n",
    "\n",
    "- **Z-Scores** rely on the assumption that the sampling distribution is normal and that the variability of the population is precisely known. These conditions make z-scores ideal for large, well-understood datasets.\n",
    "- **T-Scores** adjust for the additional uncertainty introduced when \\( \\sigma \\) is unknown, especially for small samples. The heavier tails of the t-distribution reflect this uncertainty, reducing the likelihood of underestimating variability.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary of Application**\n",
    "\n",
    "- **Use z-scores** when:\n",
    "  - \\( \\sigma \\) is known, or\n",
    "  - The sample size is large (\\( n > 30 \\)).\n",
    "\n",
    "- **Use t-scores** when:\n",
    "  - \\( \\sigma \\) is unknown, and\n",
    "  - The sample size is small (\\( n \\leq 30 \\)).\n",
    "\n",
    "As the sample size increases, the t-distribution converges to the standard normal distribution, making the distinction less critical for larger samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b222af33-c1a0-4e8e-a0b5-e35c314313ce",
   "metadata": {},
   "source": [
    "Q9->  Given a sample mean of 105, a population mean of 100, a standard deviation of 15, and a sample\n",
    "size of 25, calculate the z-score and p-value. Based on a significance level of 0.05, do you reject or fail to\n",
    "reject the null hypothesis?\n",
    "\n",
    " Task: Write Python code to calculate the z-score and p-value for the given data.\n",
    "\n",
    "Objective: Apply the formula for the z-score and interpret the p-value for hypothesis testing\n",
    "\n",
    "ANS->\n",
    "### **Results**\n",
    "- **Z-Score:** 1.67 (rounded to two decimal places)\n",
    "- **P-Value:** 0.096 (rounded to three decimal places)\n",
    "- **Decision:** Fail to reject the null hypothesis.\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation**\n",
    "1. The z-score of 1.67 indicates that the sample mean is 1.67 standard errors above the population mean.\n",
    "2. The p-value of 0.096 is greater than the significance level of 0.05, meaning there is insufficient evidence to reject the null hypothesis at the 5% level.\n",
    "\n",
    "### **Conclusion**\n",
    "At a significance level of 0.05, you **fail to reject the null hypothesis**. This suggests that the observed difference between the sample mean (105) and the population mean (100) is not statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9543e0c7-e3a1-4b97-88af-cb71f9d6352c",
   "metadata": {},
   "source": [
    "Q10->: Simulate a binomial distribution with 10 trials and a probability of success of 0.6 using Python.\n",
    "Generate 1,000 samples and plot the distribution. What is the expected mean and variance?\n",
    "\n",
    "Task: Use Python to generate the data, plot the distribution, and calculate the mean and variance.\n",
    "\n",
    "Objective: Understand the properties of a binomial distribution and verify them through simulation.\n",
    "\n",
    "\n",
    "ANS->\n",
    "\n",
    "### **Results**\n",
    "\n",
    "1. **Sample Mean:** 6.06  \n",
    "2. **Sample Variance:** 2.4264  \n",
    "3. **Expected Mean:** 6.0  \n",
    "4. **Expected Variance:** 2.4  \n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation**\n",
    "- The expected mean and variance for a binomial distribution with \\( n = 10 \\) and \\( p = 0.6 \\) are:\n",
    "  \\[\n",
    "  \\text{Mean} = n \\cdot p = 10 \\cdot 0.6 = 6.0\n",
    "  \\]\n",
    "  \\[\n",
    "  \\text{Variance} = n \\cdot p \\cdot (1 - p) = 10 \\cdot 0.6 \\cdot 0.4 = 2.4\n",
    "  \\]\n",
    "\n",
    "- The simulated mean (6.06) and variance (2.4264) closely match the expected values, confirming the properties of the binomial distribution.\n",
    "\n",
    "- The histogram shows the distribution of successes across 1,000 samples, illustrating the shape of a binomial distribution with \\( n = 10 \\) and \\( p = 0.6 \\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d961b-3947-493f-885d-45942fde095e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
